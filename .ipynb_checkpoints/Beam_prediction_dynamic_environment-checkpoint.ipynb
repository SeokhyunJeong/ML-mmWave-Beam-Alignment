{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Yuqiang (Ethan) Heng\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def cart2sph(xyz,center):\n",
    "    x = np.subtract(xyz[:,0],center[0])\n",
    "    y = np.subtract(xyz[:,1],center[1])\n",
    "    z = np.subtract(xyz[:,2],center[2])\n",
    "    rtp = np.zeros(xyz.shape)\n",
    "    r = np.sqrt(np.power(x,2)+np.power(y,2)+np.power(z,2))\n",
    "    theta = np.arccos(np.divide(z,r))\n",
    "    phi = np.arctan2(y,x)\n",
    "    rtp[:,0] = r\n",
    "    rtp[:,1] = theta\n",
    "    rtp[:,2] = phi\n",
    "    return rtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_noise = 2.0409 # noise in the cartesian coordinates of UEs\n",
    "shuffled_sa_idx = np.random.permutation(np.arange(100)+1)\n",
    "ntrain_datasets = 80   \n",
    "nval_datasets = 10\n",
    "ntest_datasets = 10\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_val = []\n",
    "Y_val = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "bf_gains_train = []\n",
    "bf_gains_val = []\n",
    "bf_gains_test = []\n",
    "prev_dataset = []\n",
    "for j in range(100):\n",
    "    data_fname = './Dataset/Dynamic_MISO_ULA_dense_polar_SA_%d.npy'%shuffled_sa_idx[j]\n",
    "    dataset = np.load(data_fname)\n",
    "    X_cart = np.copy(dataset[:,0:3])\n",
    "    Y = np.copy(dataset[:,3])\n",
    "    cartesian_x = np.multiply(np.multiply(dataset[:,0],np.sin(dataset[:,1])),np.cos(dataset[:,2]))\n",
    "    cartesian_y = np.multiply(np.multiply(dataset[:,0],np.sin(dataset[:,1])),np.sin(dataset[:,2]))\n",
    "    cartesian_z = np.multiply(dataset[:,0],np.cos(dataset[:,1]))\n",
    "    X_cart[:,0] = cartesian_x + 641\n",
    "    X_cart[:,1] = cartesian_y + 435\n",
    "    X_cart[:,2] = cartesian_z + 10\n",
    "    # add noise to cartesian coordinates\n",
    "    X = X_cart + np.random.normal(0,loc_noise,X_cart.shape)\n",
    "    X = cart2sph(X, [641,435,10])\n",
    "    prev_dataset = dataset\n",
    "    nbeam = 64\n",
    "    nvalid_rx = dataset.shape[0]\n",
    "    bf_rx_per_beam = {i:[] for i in range(nbeam)}\n",
    "    for i in range(nvalid_rx):\n",
    "        bf_rx_per_beam[int(Y[i])].append(i)\n",
    "    test_ratio = 1/100    \n",
    "    test_rx_idx = []\n",
    "    true_valid_beam = []\n",
    "    prev_valid_beam = []\n",
    "    for i in range(nbeam):\n",
    "        if len(bf_rx_per_beam[i]) >= 10:\n",
    "            sampled_inst = np.random.choice(bf_rx_per_beam[i], int(np.floor(test_ratio*len(bf_rx_per_beam[i]))), replace = False)\n",
    "            for k in sampled_inst:\n",
    "                test_rx_idx.append(k)\n",
    "    X_sampled = X[test_rx_idx,:]\n",
    "    Y_sampled = Y[test_rx_idx]\n",
    "\n",
    "    if j < ntrain_datasets:\n",
    "        if j==0:\n",
    "            X_train = X_sampled\n",
    "            Y_train = Y_sampled\n",
    "        else:\n",
    "            X_train = np.concatenate([X_train,X_sampled],axis = 0)\n",
    "            Y_train = np.concatenate([Y_train,Y_sampled],axis = 0)\n",
    "    elif j < ntrain_datasets + nval_datasets:\n",
    "        if j==ntrain_datasets:\n",
    "            X_val = X_sampled\n",
    "            Y_val = Y_sampled\n",
    "        else:\n",
    "            X_val = np.concatenate([X_val,X_sampled],axis = 0)\n",
    "            Y_val = np.concatenate([Y_val,Y_sampled],axis = 0)\n",
    "    else:\n",
    "        if j==ntrain_datasets + nval_datasets:\n",
    "            X_test = X_sampled\n",
    "            Y_test = Y_sampled\n",
    "        else:\n",
    "            X_test = np.concatenate([X_test,X_sampled],axis = 0)\n",
    "            Y_test = np.concatenate([Y_test,Y_sampled],axis = 0)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(np.concatenate((Y_train, Y_test, Y_val),0))\n",
    "Y_train_onehot = np_utils.to_categorical(encoder.transform(Y_train))\n",
    "Y_val_onehot = np_utils.to_categorical(encoder.transform(Y_val))\n",
    "Y_test_onehot = np_utils.to_categorical(encoder.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "input_location = Input(shape=(3,))\n",
    "dense1 = Dense(6, activation ='sigmoid')(input_location)\n",
    "dense2 = Dense(18, activation = 'sigmoid')(dense1)\n",
    "dense3 = Dense(48, activation = 'sigmoid')(dense2)\n",
    "output = Dense(Y_train_onehot.shape[1], activation = 'softmax')(dense3)\n",
    "model = Model(inputs = input_location, outputs = output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train_onehot, validation_data = (X_val, Y_val_onehot), epochs = 20, batch_size = 100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
